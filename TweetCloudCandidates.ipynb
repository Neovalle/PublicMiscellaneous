{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy\n",
    "!pip install textblob\n",
    "!pip install wordcloud\n",
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importa la librería tweepy y WordCloud\n",
    "import tweepy\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importa sleep, datetime, TextBlob, pandas y matplotlib\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define las variables para el acceso al API de twitter\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se autentica en twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo\n"
     ]
    }
   ],
   "source": [
    "#se verifica que el usuario conectado en twitter es de uno\n",
    "print(api.me().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devuelve el nombre del usuario de la cuenta twitter que se está usando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se pregunta por la palabra a preguntar\n",
    "palabra = \"Raffo\" #input(\"Buscar: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define la cantida de tweets a capturar\n",
    "numero_de_Tweets = 1000 #int(input(u\"Número de tweets a capturar: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el idioma de los tweets a analizar\n",
    "lenguaje = \"es\" #input(\"Idioma [es/en]:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_Raffo=api.user_timeline(screen_name='@lauraraffo', lang='es', count=200, tweet_mode='extended')\n",
    "posts_Cosse=api.user_timeline(screen_name='@CosseCarolina', lang='es', count=200, tweet_mode='extended')\n",
    "posts_Martinez=api.user_timeline(screen_name='@Dmartinez_uy', lang='es', count=200, tweet_mode='extended')\n",
    "posts_Villar=api.user_timeline(screen_name='@alvillar', lang='es', count=200, tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Candidato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conversamos con la directiva y recorrimos las ...</td>\n",
       "      <td>Raffo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Felicitamos el trabajo que está haciendo la fu...</td>\n",
       "      <td>Raffo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queremos entrar en acción, hay mucho por hacer...</td>\n",
       "      <td>Raffo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nos reunimos con el Centro de Panaderos y repa...</td>\n",
       "      <td>Raffo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ayer recibí a la Unión de Vecinos de Ferias. H...</td>\n",
       "      <td>Raffo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>RT @MPP609: Hoy estuvimos recorriendo varios p...</td>\n",
       "      <td>Villar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>RT @MPP609: Gracias infinitas a toda la gente ...</td>\n",
       "      <td>Villar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>RT @MPP609: Para cerrar la jornada, estuvimos ...</td>\n",
       "      <td>Villar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>RT @Mario_Bergara: Curiosa forma de hacer camp...</td>\n",
       "      <td>Villar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>RT @SusanaCamaran: #ElAcentoEnElDeporte\\n#ElAc...</td>\n",
       "      <td>Villar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet Candidato\n",
       "0    Conversamos con la directiva y recorrimos las ...     Raffo\n",
       "1    Felicitamos el trabajo que está haciendo la fu...     Raffo\n",
       "2    Queremos entrar en acción, hay mucho por hacer...     Raffo\n",
       "3    Nos reunimos con el Centro de Panaderos y repa...     Raffo\n",
       "4    Ayer recibí a la Unión de Vecinos de Ferias. H...     Raffo\n",
       "..                                                 ...       ...\n",
       "794  RT @MPP609: Hoy estuvimos recorriendo varios p...    Villar\n",
       "795  RT @MPP609: Gracias infinitas a toda la gente ...    Villar\n",
       "796  RT @MPP609: Para cerrar la jornada, estuvimos ...    Villar\n",
       "797  RT @Mario_Bergara: Curiosa forma de hacer camp...    Villar\n",
       "798  RT @SusanaCamaran: #ElAcentoEnElDeporte\\n#ElAc...    Villar\n",
       "\n",
       "[799 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for tweet in posts:\n",
    "#    print(tweet.full_text)\n",
    "\n",
    "# initialize data frame with one candidate\n",
    "df=pd.DataFrame({'Tweet':[tweet.full_text for tweet in posts_Raffo],'Candidato':\"Raffo\"})\n",
    "\n",
    "# create temp data frames\n",
    "df_Cosse=pd.DataFrame({'Tweet':[tweet.full_text for tweet in posts_Cosse],'Candidato':\"Cosse\"})\n",
    "df_Martinez=pd.DataFrame({'Tweet':[tweet.full_text for tweet in posts_Martinez],'Candidato':\"Martinez\"})\n",
    "df_Villar=pd.DataFrame({'Tweet':[tweet.full_text for tweet in posts_Villar],'Candidato':\"Villar\"})\n",
    "\n",
    "# append to main data frame\n",
    "df=df.append(df_Cosse, ignore_index=True)\n",
    "df=df.append(df_Martinez, ignore_index=True)\n",
    "df=df.append(df_Villar, ignore_index=True)\n",
    "\n",
    "#df= df.append({'Tweet':[tweet.full_text for tweet in posts_Martinez],'Candidato':\"Martinez\"}, ignore_index=True)\n",
    "#df= df.append({'Tweet':[tweet.full_text for tweet in posts_Villar],'Candidato':\"Villar\"}, ignore_index=True)\n",
    "#stopwords_ES = set(stopwords.words('spanish'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text\n",
    "\n",
    "#Create a function to clean the tweets\n",
    "\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # Removed @mentions\n",
    "    text = re.sub(r'#', '', text) #Removing the '#' symbol\n",
    "    text = re.sub(r'RT[\\s]+', '', text) # Removing RT\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # Remove the hyper link\n",
    "    text = re.sub(r'_[A-Za-z0-9]+', '', text) # Removed @mentions\n",
    "    return text\n",
    "\n",
    "#Cleaning the text\n",
    "\n",
    "df['Tweet']= df['Tweet'].apply(cleanTxt)\n",
    "\n",
    "#Show the cleaned text\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fc234dd47d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generateCloud(candidato):\n",
    "\n",
    "    allWords = ' '.join( [twts for twts in df['Tweet'].loc[df['Candidato'] == candidato] ])\n",
    "\n",
    "    #wordCloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', colormap='Set1', collocations=False, \n",
    "                     # stopwords = stopwords_ES, max_words= 80).generate(allWords)\n",
    "\n",
    "    return WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', colormap='tab20b', collocations=False, \n",
    "                      stopwords = stopwords_ES, max_words= 80).generate(allWords)\n",
    "\n",
    "wordCloud=generateCloud(\"Cosse\")\n",
    "wordCloud.to_file(\"Cosse.png\")\n",
    "\n",
    "wordCloud=generateCloud(\"Raffo\")\n",
    "wordCloud.to_file(\"Raffo.png\")\n",
    "\n",
    "wordCloud=generateCloud(\"Martinez\")\n",
    "wordCloud.to_file(\"Martinez.png\")\n",
    "\n",
    "wordCloud=generateCloud(\"Villar\")\n",
    "wordCloud.to_file(\"Villar.png\")\n",
    "\n",
    "\n",
    "#plt.imshow(wordCloud, interpolation= \"bilinear\")\n",
    "#plt.axis('off')\n",
    "#plt.show\n",
    "#wordCloud.to_file(\"Carolina.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
